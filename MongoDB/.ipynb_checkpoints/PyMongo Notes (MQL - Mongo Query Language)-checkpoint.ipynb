{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fbc0818",
   "metadata": {},
   "source": [
    "## Establishing connection of MongoDB driver with Python\n",
    "\n",
    "Pymongo library in Python is required for establishing connection with MongoDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7955a95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pymongo[srv] Package for connecting mongo compass to Python\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "from pprint import pprint # Package used for printing JSON format with clear structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa54a427",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient('mongodb+srv://admin:Aikseng1163@mydb.h2tun.mongodb.net/test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5c75b8",
   "metadata": {},
   "source": [
    "Note that the MongoClient above is based on connection string from Mongo Atlas (Cloud service of MongoDB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c069f36e",
   "metadata": {},
   "source": [
    "## Basic Operations of PyMongo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b5c5fe",
   "metadata": {},
   "source": [
    "### 1. Viewing list of available databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67c31959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample_airbnb',\n",
       " 'sample_analytics',\n",
       " 'sample_geospatial',\n",
       " 'sample_mflix',\n",
       " 'sample_restaurants',\n",
       " 'sample_supplies',\n",
       " 'sample_training',\n",
       " 'sample_weatherdata',\n",
       " 'admin',\n",
       " 'local']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.list_database_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8ce673",
   "metadata": {},
   "source": [
    "### 2. Using specific database for further operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93a0396d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = client['sample_training']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe0eabe",
   "metadata": {},
   "source": [
    "Note that using a new database that does not exist in the MongoClient is still possible, however a database will only be created once documents are created in a collection within the database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f0479b",
   "metadata": {},
   "source": [
    "### 3. Viewing list of available collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b83321a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['zips', 'companies', 'routes', 'grades', 'posts', 'trips', 'inspections']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.list_collection_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048425f0",
   "metadata": {},
   "source": [
    "### 4. Viewing stats of database and collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd6b2692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'db': 'sample_training',\n",
       " 'collections': 7,\n",
       " 'views': 0,\n",
       " 'objects': 296502,\n",
       " 'avgObjSize': 402.31109739563306,\n",
       " 'dataSize': 119286045,\n",
       " 'storageSize': 49717248,\n",
       " 'totalFreeStorageSize': 0,\n",
       " 'numExtents': 0,\n",
       " 'indexes': 7,\n",
       " 'indexSize': 4034560,\n",
       " 'fileSize': 0,\n",
       " 'nsSizeMB': 0,\n",
       " 'ok': 1}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.command('dbstats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a5970c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ns': 'sample_training.routes',\n",
       " 'size': 12333561,\n",
       " 'count': 66985,\n",
       " 'avgObjSize': 184,\n",
       " 'storageSize': 3125248,\n",
       " 'freeStorageSize': 946176,\n",
       " 'capped': False,\n",
       " 'nindexes': 1,\n",
       " 'indexDetails': {'_id_': {'metadata': {'formatVersion': 8},\n",
       "   'creationString': 'access_pattern_hint=none,allocation_size=4KB,app_metadata=(formatVersion=8),assert=(commit_timestamp=none,durable_timestamp=none,read_timestamp=none,write_timestamp=off),block_allocation=best,block_compressor=,cache_resident=false,checksum=on,colgroups=,collator=,columns=,dictionary=0,encryption=(keyid=,name=),exclusive=false,extractor=,format=btree,huffman_key=,huffman_value=,ignore_in_memory_cache_size=false,immutable=false,import=(enabled=false,file_metadata=,repair=false),internal_item_max=0,internal_key_max=0,internal_key_truncate=true,internal_page_max=16k,key_format=u,key_gap=10,leaf_item_max=0,leaf_key_max=0,leaf_page_max=16k,leaf_value_max=0,log=(enabled=false),lsm=(auto_throttle=true,bloom=true,bloom_bit_count=16,bloom_config=,bloom_hash_count=8,bloom_oldest=false,chunk_count_limit=0,chunk_max=5GB,chunk_size=10MB,merge_custom=(prefix=,start_generation=0,suffix=),merge_max=15,merge_min=0),memory_page_image_max=0,memory_page_max=5MB,os_cache_dirty_max=0,os_cache_max=0,prefix_compression=true,prefix_compression_min=4,readonly=false,source=,split_deepen_min_child=0,split_deepen_per_child=0,split_pct=90,tiered_object=false,tiered_storage=(auth_token=,bucket=,bucket_prefix=,local_retention=300,name=,object_target_size=10M),type=file,value_format=u,verbose=[],write_timestamp_usage=none',\n",
       "   'type': 'file',\n",
       "   'uri': 'statistics:table:index-35984-4954907044630669634',\n",
       "   'LSM': {'bloom filter false positives': 0,\n",
       "    'bloom filter hits': 0,\n",
       "    'bloom filter misses': 0,\n",
       "    'bloom filter pages evicted from cache': 0,\n",
       "    'bloom filter pages read into cache': 0,\n",
       "    'bloom filters in the LSM tree': 0,\n",
       "    'chunks in the LSM tree': 0,\n",
       "    'highest merge generation in the LSM tree': 0,\n",
       "    'queries that could have benefited from a Bloom filter that did not exist': 0,\n",
       "    'sleep for LSM checkpoint throttle': 0,\n",
       "    'sleep for LSM merge throttle': 0,\n",
       "    'total size of bloom filters': 0},\n",
       "   'block-manager': {'allocations requiring file extension': 0,\n",
       "    'blocks allocated': 0,\n",
       "    'blocks freed': 0,\n",
       "    'checkpoint size': 663552,\n",
       "    'file allocation unit size': 4096,\n",
       "    'file bytes available for reuse': 258048,\n",
       "    'file magic number': 120897,\n",
       "    'file major version number': 1,\n",
       "    'file size in bytes': 937984,\n",
       "    'minor version number': 0},\n",
       "   'btree': {'btree checkpoint generation': 0,\n",
       "    'btree clean tree checkpoint expiration time': 0,\n",
       "    'column-store fixed-size leaf pages': 0,\n",
       "    'column-store internal pages': 0,\n",
       "    'column-store variable-size RLE encoded values': 0,\n",
       "    'column-store variable-size deleted values': 0,\n",
       "    'column-store variable-size leaf pages': 0,\n",
       "    'fixed-record size': 0,\n",
       "    'maximum internal page key size': 1474,\n",
       "    'maximum internal page size': 16384,\n",
       "    'maximum leaf page key size': 1474,\n",
       "    'maximum leaf page size': 16384,\n",
       "    'maximum leaf page value size': 7372,\n",
       "    'maximum tree depth': 0,\n",
       "    'number of key/value pairs': 0,\n",
       "    'overflow pages': 0,\n",
       "    'pages rewritten by compaction': 0,\n",
       "    'row-store empty values': 0,\n",
       "    'row-store internal pages': 0,\n",
       "    'row-store leaf pages': 0},\n",
       "   'cache': {'bytes currently in the cache': 3713,\n",
       "    'bytes dirty in the cache cumulative': 0,\n",
       "    'bytes read into cache': 1038,\n",
       "    'bytes written from cache': 0,\n",
       "    'checkpoint blocked page eviction': 0,\n",
       "    'checkpoint of history store file blocked non-history store page eviction': 0,\n",
       "    'data source pages selected for eviction unable to be evicted': 0,\n",
       "    'eviction gave up due to detecting an out of order on disk value behind the last update on the chain': 0,\n",
       "    'eviction gave up due to detecting an out of order tombstone ahead of the selected on disk update': 0,\n",
       "    'eviction gave up due to detecting an out of order tombstone ahead of the selected on disk update after validating the update chain': 0,\n",
       "    'eviction gave up due to detecting out of order timestamps on the update chain after the selected on disk update': 0,\n",
       "    'eviction walk passes of a file': 0,\n",
       "    'eviction walk target pages histogram - 0-9': 0,\n",
       "    'eviction walk target pages histogram - 10-31': 0,\n",
       "    'eviction walk target pages histogram - 128 and higher': 0,\n",
       "    'eviction walk target pages histogram - 32-63': 0,\n",
       "    'eviction walk target pages histogram - 64-128': 0,\n",
       "    'eviction walk target pages reduced due to history store cache pressure': 0,\n",
       "    'eviction walks abandoned': 0,\n",
       "    'eviction walks gave up because they restarted their walk twice': 0,\n",
       "    'eviction walks gave up because they saw too many pages and found no candidates': 0,\n",
       "    'eviction walks gave up because they saw too many pages and found too few candidates': 0,\n",
       "    'eviction walks reached end of tree': 0,\n",
       "    'eviction walks restarted': 0,\n",
       "    'eviction walks started from root of tree': 0,\n",
       "    'eviction walks started from saved location in tree': 0,\n",
       "    'hazard pointer blocked page eviction': 0,\n",
       "    'history store table insert calls': 0,\n",
       "    'history store table insert calls that returned restart': 0,\n",
       "    'history store table out-of-order resolved updates that lose their durable timestamp': 0,\n",
       "    'history store table out-of-order updates that were fixed up by reinserting with the fixed timestamp': 0,\n",
       "    'history store table reads': 0,\n",
       "    'history store table reads missed': 0,\n",
       "    'history store table reads requiring squashed modifies': 0,\n",
       "    'history store table truncation by rollback to stable to remove an unstable update': 0,\n",
       "    'history store table truncation by rollback to stable to remove an update': 0,\n",
       "    'history store table truncation to remove an update': 0,\n",
       "    'history store table truncation to remove range of updates due to key being removed from the data page during reconciliation': 0,\n",
       "    'history store table truncation to remove range of updates due to out-of-order timestamp update on data page': 0,\n",
       "    'history store table writes requiring squashed modifies': 0,\n",
       "    'in-memory page passed criteria to be split': 0,\n",
       "    'in-memory page splits': 0,\n",
       "    'internal pages evicted': 0,\n",
       "    'internal pages split during eviction': 0,\n",
       "    'leaf pages split during eviction': 0,\n",
       "    'modified pages evicted': 0,\n",
       "    'overflow pages read into cache': 0,\n",
       "    'page split during eviction deepened the tree': 0,\n",
       "    'page written requiring history store records': 0,\n",
       "    'pages read into cache': 1,\n",
       "    'pages read into cache after truncate': 0,\n",
       "    'pages read into cache after truncate in prepare state': 0,\n",
       "    'pages requested from the cache': 0,\n",
       "    'pages seen by eviction walk': 0,\n",
       "    'pages written from cache': 0,\n",
       "    'pages written requiring in-memory restoration': 0,\n",
       "    'tracked dirty bytes in the cache': 0,\n",
       "    'unmodified pages evicted': 0},\n",
       "   'cache_walk': {'Average difference between current eviction generation when the page was last considered': 0,\n",
       "    'Average on-disk page image size seen': 0,\n",
       "    'Average time in cache for pages that have been visited by the eviction server': 0,\n",
       "    'Average time in cache for pages that have not been visited by the eviction server': 0,\n",
       "    'Clean pages currently in cache': 0,\n",
       "    'Current eviction generation': 0,\n",
       "    'Dirty pages currently in cache': 0,\n",
       "    'Entries in the root page': 0,\n",
       "    'Internal pages currently in cache': 0,\n",
       "    'Leaf pages currently in cache': 0,\n",
       "    'Maximum difference between current eviction generation when the page was last considered': 0,\n",
       "    'Maximum page size seen': 0,\n",
       "    'Minimum on-disk page image size seen': 0,\n",
       "    'Number of pages never visited by eviction server': 0,\n",
       "    'On-disk page image sizes smaller than a single allocation unit': 0,\n",
       "    'Pages created in memory and never written': 0,\n",
       "    'Pages currently queued for eviction': 0,\n",
       "    'Pages that could not be queued for eviction': 0,\n",
       "    'Refs skipped during cache traversal': 0,\n",
       "    'Size of the root page': 0,\n",
       "    'Total number of pages currently in cache': 0},\n",
       "   'checkpoint-cleanup': {'pages added for eviction': 0,\n",
       "    'pages removed': 0,\n",
       "    'pages skipped during tree walk': 0,\n",
       "    'pages visited': 0},\n",
       "   'compression': {'compressed page maximum internal page size prior to compression': 16384,\n",
       "    'compressed page maximum leaf page size prior to compression ': 16384,\n",
       "    'compressed pages read': 0,\n",
       "    'compressed pages written': 0,\n",
       "    'page written failed to compress': 0,\n",
       "    'page written was too small to compress': 0},\n",
       "   'cursor': {'Total number of entries skipped by cursor next calls': 0,\n",
       "    'Total number of entries skipped by cursor prev calls': 0,\n",
       "    'Total number of entries skipped to position the history store cursor': 0,\n",
       "    'Total number of times a search near has exited due to prefix config': 0,\n",
       "    'bulk loaded cursor insert calls': 0,\n",
       "    'cache cursors reuse count': 0,\n",
       "    'close calls that result in cache': 0,\n",
       "    'create calls': 0,\n",
       "    'cursor next calls that skip due to a globally visible history store tombstone': 0,\n",
       "    'cursor next calls that skip greater than or equal to 100 entries': 0,\n",
       "    'cursor next calls that skip less than 100 entries': 0,\n",
       "    'cursor prev calls that skip due to a globally visible history store tombstone': 0,\n",
       "    'cursor prev calls that skip greater than or equal to 100 entries': 0,\n",
       "    'cursor prev calls that skip less than 100 entries': 0,\n",
       "    'insert calls': 0,\n",
       "    'insert key and value bytes': 0,\n",
       "    'modify': 0,\n",
       "    'modify key and value bytes affected': 0,\n",
       "    'modify value bytes modified': 0,\n",
       "    'next calls': 0,\n",
       "    'open cursor count': 0,\n",
       "    'operation restarted': 0,\n",
       "    'prev calls': 0,\n",
       "    'remove calls': 0,\n",
       "    'remove key bytes removed': 0,\n",
       "    'reserve calls': 0,\n",
       "    'reset calls': 0,\n",
       "    'search calls': 0,\n",
       "    'search history store calls': 0,\n",
       "    'search near calls': 0,\n",
       "    'truncate calls': 0,\n",
       "    'update calls': 0,\n",
       "    'update key and value bytes': 0,\n",
       "    'update value size change': 0},\n",
       "   'reconciliation': {'approximate byte size of timestamps in pages written': 0,\n",
       "    'approximate byte size of transaction IDs in pages written': 0,\n",
       "    'dictionary matches': 0,\n",
       "    'fast-path pages deleted': 0,\n",
       "    'internal page key bytes discarded using suffix compression': 0,\n",
       "    'internal page multi-block writes': 0,\n",
       "    'internal-page overflow keys': 0,\n",
       "    'leaf page key bytes discarded using prefix compression': 0,\n",
       "    'leaf page multi-block writes': 0,\n",
       "    'leaf-page overflow keys': 0,\n",
       "    'maximum blocks required for a page': 0,\n",
       "    'overflow values written': 0,\n",
       "    'page checksum matches': 0,\n",
       "    'page reconciliation calls': 0,\n",
       "    'page reconciliation calls for eviction': 0,\n",
       "    'pages deleted': 0,\n",
       "    'pages written including an aggregated newest start durable timestamp ': 0,\n",
       "    'pages written including an aggregated newest stop durable timestamp ': 0,\n",
       "    'pages written including an aggregated newest stop timestamp ': 0,\n",
       "    'pages written including an aggregated newest stop transaction ID': 0,\n",
       "    'pages written including an aggregated newest transaction ID ': 0,\n",
       "    'pages written including an aggregated oldest start timestamp ': 0,\n",
       "    'pages written including an aggregated prepare': 0,\n",
       "    'pages written including at least one prepare': 0,\n",
       "    'pages written including at least one start durable timestamp': 0,\n",
       "    'pages written including at least one start timestamp': 0,\n",
       "    'pages written including at least one start transaction ID': 0,\n",
       "    'pages written including at least one stop durable timestamp': 0,\n",
       "    'pages written including at least one stop timestamp': 0,\n",
       "    'pages written including at least one stop transaction ID': 0,\n",
       "    'records written including a prepare': 0,\n",
       "    'records written including a start durable timestamp': 0,\n",
       "    'records written including a start timestamp': 0,\n",
       "    'records written including a start transaction ID': 0,\n",
       "    'records written including a stop durable timestamp': 0,\n",
       "    'records written including a stop timestamp': 0,\n",
       "    'records written including a stop transaction ID': 0},\n",
       "   'session': {'object compaction': 0,\n",
       "    'tiered operations dequeued and processed': 0,\n",
       "    'tiered operations scheduled': 0,\n",
       "    'tiered storage local retention time (secs)': 0,\n",
       "    'tiered storage object size': 0},\n",
       "   'transaction': {'race to read prepared update retry': 0,\n",
       "    'rollback to stable history store records with stop timestamps older than newer records': 0,\n",
       "    'rollback to stable inconsistent checkpoint': 0,\n",
       "    'rollback to stable keys removed': 0,\n",
       "    'rollback to stable keys restored': 0,\n",
       "    'rollback to stable restored tombstones from history store': 0,\n",
       "    'rollback to stable restored updates from history store': 0,\n",
       "    'rollback to stable skipping delete rle': 0,\n",
       "    'rollback to stable skipping stable rle': 0,\n",
       "    'rollback to stable sweeping history store keys': 0,\n",
       "    'rollback to stable updates removed from history store': 0,\n",
       "    'transaction checkpoints due to obsolete pages': 0,\n",
       "    'update conflicts': 0}}},\n",
       " 'indexBuilds': [],\n",
       " 'totalIndexSize': 937984,\n",
       " 'totalSize': 4063232,\n",
       " 'indexSizes': {'_id_': 937984},\n",
       " 'scaleFactor': 1,\n",
       " 'ok': 1.0,\n",
       " '$clusterTime': {'clusterTime': Timestamp(1634701620, 285),\n",
       "  'signature': {'hash': b'SD\\x8a\\x80\\x17\\x86f\\xc8\\xad^\\xe2H\\xda\\x07\\x186d%17',\n",
       "   'keyId': 6961454422681452546}},\n",
       " 'operationTime': Timestamp(1634701620, 285)}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.command('collstats','routes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ac4819",
   "metadata": {},
   "source": [
    "## Create Operations of MongoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee39e037",
   "metadata": {},
   "source": [
    "### 1. Create new collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "43b1dae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = training['new_sample']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e2a9c1",
   "metadata": {},
   "source": [
    "Note that using a new collection that does not exist in the MongoClient is still possible, however a collection will only be created once documents are inserted into the collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8212128",
   "metadata": {},
   "source": [
    "### 2. Inserting single document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d6d3805c",
   "metadata": {},
   "outputs": [],
   "source": [
    "singledata = sample.insert_one({'Name':'Tammy', 'Age': 27, 'Birth year': 1978, 'Job post': 'Engineer'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bde6caac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "616f94634108a89cfa3aee29\n"
     ]
    }
   ],
   "source": [
    "print(singledata.inserted_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95ef4bc",
   "metadata": {},
   "source": [
    "### 3. Inserting multiple documents (normal insert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6eb26845",
   "metadata": {},
   "outputs": [],
   "source": [
    "multidata = sample.insert_many([{'Name':'Cynthia', 'Age': 27, 'Birth year': 1978, 'Job post': 'Engineer'},\n",
    "                                {'Name':'Sharon', 'Age': 29, 'Birth year': 1993, 'Job post': 'Doctor'},\n",
    "                                {'Name':'James', 'Age': 25, 'Birth year': 2001, 'Job post': 'Surgeon'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b0b3b1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ObjectId('616f94bc4108a89cfa3aee2a'), ObjectId('616f94bc4108a89cfa3aee2b'), ObjectId('616f94bc4108a89cfa3aee2c')]\n"
     ]
    }
   ],
   "source": [
    "print(multidata.inserted_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37c92d0",
   "metadata": {},
   "source": [
    "### 4. Inserting multiple documents (bulk insert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8ebe0074",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yixia\\AppData\\Local\\Temp/ipykernel_15104/3122175329.py:1: DeprecationWarning: insert is deprecated. Use insert_one or insert_many instead.\n",
      "  multidata = sample.insert([{'Name':'Chloe', 'Age': 19, 'Birth year': 2002, 'Job post': 'Student'},\n"
     ]
    }
   ],
   "source": [
    "multidata = sample.insert([{'Name':'Chloe', 'Age': 19, 'Birth year': 2002, 'Job post': 'Student'},\n",
    "                            {'Name':'Jackson', 'Age': 24, 'Birth year': 1996, 'Job post': 'Unemployed'},\n",
    "                            {'Name':'Crempie', 'Age': 22, 'Birth year': 1998, 'Job post': 'Business Analyst'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3603d492",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ObjectId('616f95554108a89cfa3aee2d'), ObjectId('616f95554108a89cfa3aee2e'), ObjectId('616f95554108a89cfa3aee2f')]\n"
     ]
    }
   ],
   "source": [
    "print(multidata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b27721",
   "metadata": {},
   "source": [
    "Note that when inserting multiple documents, operation will end when either all documents are inserted or the current document fails to insert.\n",
    "\n",
    "<b>\"Ordered\" key value is set to \"True\" by default, such that operation will return an error as soon as one of the documents fails to insert into the collection.</b>\n",
    "\n",
    "<b>Adjusting \"Ordered\" key value to \"False\" will result in operation attempt to insert all documents specified in the list.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6702fd2",
   "metadata": {},
   "source": [
    "Observe the following example below where the second document in the list has duplicated id key error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f35c5446",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "BulkWriteError",
     "evalue": "batch op errors occurred, full error: {'writeErrors': [{'index': 1, 'code': 11000, 'keyPattern': {'_id': 1}, 'keyValue': {'_id': 1}, 'errmsg': 'E11000 duplicate key error collection: sample_training.new_sample index: _id_ dup key: { _id: 1 }', 'op': {'_id': 1, 'Name': 'Sharone', 'Age': 29, 'Birth year': 1993, 'Job post': 'Doctor'}}], 'writeConcernErrors': [], 'nInserted': 1, 'nUpserted': 0, 'nMatched': 0, 'nModified': 0, 'nRemoved': 0, 'upserted': []}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBulkWriteError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15104/2150537495.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m multidata = sample.insert_many([{'_id':1,'Name':'Christopher', 'Age': 24, 'Birth year': 1998, 'Job post': 'Chef'},\n\u001b[0m\u001b[0;32m      2\u001b[0m                                 \u001b[1;33m{\u001b[0m\u001b[1;34m'_id'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Name'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'Sharone'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Age'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m29\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Birth year'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1993\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Job post'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Doctor'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                 {'_id': 2, 'Name':'McBethy', 'Age': 31, 'Birth year': 1995, 'Job post': 'Waitress'}])\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Data_Science\\lib\\site-packages\\pymongo\\collection.py\u001b[0m in \u001b[0;36minsert_many\u001b[1;34m(self, documents, ordered, bypass_document_validation, session)\u001b[0m\n\u001b[0;32m    768\u001b[0m         \u001b[0mblk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Bulk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mordered\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbypass_document_validation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m         \u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdoc\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 770\u001b[1;33m         \u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrite_concern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    771\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mInsertManyResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minserted_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrite_concern\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macknowledged\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    772\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Data_Science\\lib\\site-packages\\pymongo\\bulk.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, write_concern, session)\u001b[0m\n\u001b[0;32m    527\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute_no_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 529\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrite_concern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Data_Science\\lib\\site-packages\\pymongo\\bulk.py\u001b[0m in \u001b[0;36mexecute_command\u001b[1;34m(self, generator, write_concern, session)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfull_result\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"writeErrors\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfull_result\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"writeConcernErrors\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 364\u001b[1;33m             \u001b[0m_raise_bulk_write_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    365\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfull_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Data_Science\\lib\\site-packages\\pymongo\\bulk.py\u001b[0m in \u001b[0;36m_raise_bulk_write_error\u001b[1;34m(full_result)\u001b[0m\n\u001b[0;32m    138\u001b[0m         full_result[\"writeErrors\"].sort(\n\u001b[0;32m    139\u001b[0m             key=lambda error: error[\"index\"])\n\u001b[1;32m--> 140\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mBulkWriteError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mBulkWriteError\u001b[0m: batch op errors occurred, full error: {'writeErrors': [{'index': 1, 'code': 11000, 'keyPattern': {'_id': 1}, 'keyValue': {'_id': 1}, 'errmsg': 'E11000 duplicate key error collection: sample_training.new_sample index: _id_ dup key: { _id: 1 }', 'op': {'_id': 1, 'Name': 'Sharone', 'Age': 29, 'Birth year': 1993, 'Job post': 'Doctor'}}], 'writeConcernErrors': [], 'nInserted': 1, 'nUpserted': 0, 'nMatched': 0, 'nModified': 0, 'nRemoved': 0, 'upserted': []}"
     ]
    }
   ],
   "source": [
    "multidata = sample.insert_many([{'_id':1,'Name':'Christopher', 'Age': 24, 'Birth year': 1998, 'Job post': 'Chef'},\n",
    "                                {'_id':1, 'Name':'Sharone', 'Age': 29, 'Birth year': 1993, 'Job post': 'Doctor'},\n",
    "                                {'_id': 2, 'Name':'McBethy', 'Age': 31, 'Birth year': 1995, 'Job post': 'Waitress'}])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac2d694",
   "metadata": {},
   "source": [
    "Note that the error above shows that the 2nd document in the list could not be inserted due to duplicated \"_id\" values. MongoDB by default creates a new \"_id\" value that is unique within a collection when not specified.\n",
    "\n",
    "Therefore, only the first document is inserted into the collection (where <b>nInserted value is 1</b>)\n",
    "\n",
    "The example below demonstrates the insert operation with ordered value set to False:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e8554954",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "BulkWriteError",
     "evalue": "batch op errors occurred, full error: {'writeErrors': [{'index': 1, 'code': 11000, 'keyPattern': {'_id': 1}, 'keyValue': {'_id': 2}, 'errmsg': 'E11000 duplicate key error collection: sample_training.new_sample index: _id_ dup key: { _id: 2 }', 'op': {'_id': 2, 'Name': 'Salmon', 'Age': 29, 'Birth year': 1993, 'Job post': 'Doctor'}}], 'writeConcernErrors': [], 'nInserted': 2, 'nUpserted': 0, 'nMatched': 0, 'nModified': 0, 'nRemoved': 0, 'upserted': []}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBulkWriteError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15104/3353624055.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m multidata = sample.insert_many([{'_id':2,'Name':'Sharone', 'Age': 24, 'Birth year': 1998, 'Job post': 'Truck driver'},\n\u001b[0m\u001b[0;32m      2\u001b[0m                                 \u001b[1;33m{\u001b[0m\u001b[1;34m'_id'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Name'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'Salmon'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Age'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m29\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Birth year'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1993\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Job post'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Doctor'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                 {'_id': 3, 'Name':'McBethy', 'Age': 31, 'Birth year': 1995, 'Job post': 'Waitress'}], ordered=False)\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Data_Science\\lib\\site-packages\\pymongo\\collection.py\u001b[0m in \u001b[0;36minsert_many\u001b[1;34m(self, documents, ordered, bypass_document_validation, session)\u001b[0m\n\u001b[0;32m    768\u001b[0m         \u001b[0mblk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Bulk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mordered\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbypass_document_validation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m         \u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdoc\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 770\u001b[1;33m         \u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrite_concern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    771\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mInsertManyResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minserted_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrite_concern\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macknowledged\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    772\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Data_Science\\lib\\site-packages\\pymongo\\bulk.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, write_concern, session)\u001b[0m\n\u001b[0;32m    527\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute_no_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 529\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrite_concern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Data_Science\\lib\\site-packages\\pymongo\\bulk.py\u001b[0m in \u001b[0;36mexecute_command\u001b[1;34m(self, generator, write_concern, session)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfull_result\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"writeErrors\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfull_result\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"writeConcernErrors\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 364\u001b[1;33m             \u001b[0m_raise_bulk_write_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    365\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfull_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Data_Science\\lib\\site-packages\\pymongo\\bulk.py\u001b[0m in \u001b[0;36m_raise_bulk_write_error\u001b[1;34m(full_result)\u001b[0m\n\u001b[0;32m    138\u001b[0m         full_result[\"writeErrors\"].sort(\n\u001b[0;32m    139\u001b[0m             key=lambda error: error[\"index\"])\n\u001b[1;32m--> 140\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mBulkWriteError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mBulkWriteError\u001b[0m: batch op errors occurred, full error: {'writeErrors': [{'index': 1, 'code': 11000, 'keyPattern': {'_id': 1}, 'keyValue': {'_id': 2}, 'errmsg': 'E11000 duplicate key error collection: sample_training.new_sample index: _id_ dup key: { _id: 2 }', 'op': {'_id': 2, 'Name': 'Salmon', 'Age': 29, 'Birth year': 1993, 'Job post': 'Doctor'}}], 'writeConcernErrors': [], 'nInserted': 2, 'nUpserted': 0, 'nMatched': 0, 'nModified': 0, 'nRemoved': 0, 'upserted': []}"
     ]
    }
   ],
   "source": [
    "multidata = sample.insert_many([{'_id':2,'Name':'Sharone', 'Age': 24, 'Birth year': 1998, 'Job post': 'Truck driver'},\n",
    "                                {'_id':2, 'Name':'Salmon', 'Age': 29, 'Birth year': 1993, 'Job post': 'Doctor'},\n",
    "                                {'_id': 3, 'Name':'McBethy', 'Age': 31, 'Birth year': 1995, 'Job post': 'Waitress'}], \n",
    "                               ordered=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ac8c0f",
   "metadata": {},
   "source": [
    "Note that the error above also shows that the 2nd document in the list could not be inserted due to duplicated \"_id\" values. \n",
    "However, when \"ordered\" value is set to False, the operation skips the 2nd document and attempts to insert the third document into the collection which is a success.\n",
    "\n",
    "Therefore, only the first and third document is inserted into the collection (where <b>nInserted value is 2</b>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fca6f58",
   "metadata": {},
   "source": [
    "## Update Operations of MongoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c230e30b",
   "metadata": {},
   "source": [
    "### 1. Replace entire single document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "233a5cbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': 3,\n",
       "  'Name': 'McBethy',\n",
       "  'Age': 31,\n",
       "  'Birth year': 1995,\n",
       "  'Job post': 'Waitress'}]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before replacement\n",
    "list(sample.find({'Name':'McBethy'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ede04db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "replace = sample.replace_one({'Name': 'McBethy'},{'Name': 'McBethy','Age':27, 'Occupation': 'Doctor', 'Income': 27000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "27225121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n': 1,\n",
       " 'nModified': 1,\n",
       " 'opTime': {'ts': Timestamp(1634704707, 1), 't': 106},\n",
       " 'electionId': ObjectId('7fffffff000000000000006a'),\n",
       " 'ok': 1.0,\n",
       " '$clusterTime': {'clusterTime': Timestamp(1634704707, 1),\n",
       "  'signature': {'hash': b\"\\xcb\\x07\\xf9\\x1a$5h\\x00\\xb6\\x86\\x80'5\\xc3t\\xa3\\x17;i\\xb0\",\n",
       "   'keyId': 6961454422681452546}},\n",
       " 'operationTime': Timestamp(1634704707, 1),\n",
       " 'updatedExisting': True}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace.raw_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "02592a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': 3,\n",
       "  'Name': 'McBethy',\n",
       "  'Age': 27,\n",
       "  'Occupation': 'Doctor',\n",
       "  'Income': 27000}]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After replacement\n",
    "list(sample.find({'Name':'McBethy'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055fec7a",
   "metadata": {},
   "source": [
    "As shown above, the entire document structure other than \"_id\" variable for a single document can be replaced with a new document by first filtering the document that satisfies the specified condition before specifying the new document. Note that this operation is not supported for multiple documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67a75c9",
   "metadata": {},
   "source": [
    "### 2. Update part of single document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b91de952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': 2,\n",
       "  'Name': 'Sharone',\n",
       "  'Age': 24,\n",
       "  'Birth year': 1998,\n",
       "  'Job post': 'Truck driver'}]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before update\n",
    "list(sample.find({'Name':'Sharone'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "04aa0645",
   "metadata": {},
   "outputs": [],
   "source": [
    "singleupdate = sample.update_one({'Name': 'Sharone'},{'$set':{'Job post': 'Truck operator'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "147077ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n': 1,\n",
       " 'nModified': 1,\n",
       " 'opTime': {'ts': Timestamp(1634719103, 1), 't': 106},\n",
       " 'electionId': ObjectId('7fffffff000000000000006a'),\n",
       " 'ok': 1.0,\n",
       " '$clusterTime': {'clusterTime': Timestamp(1634719103, 1),\n",
       "  'signature': {'hash': b'lr\\xeaZh\\xc0\\x99$\\xde\\x8ev\\x84\\xfd\\x07\\xaf\\xf0\\xafK\\xea\\xf6',\n",
       "   'keyId': 6961454422681452546}},\n",
       " 'operationTime': Timestamp(1634719103, 1),\n",
       " 'updatedExisting': True}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "singleupdate.raw_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9a9b199d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': 2,\n",
       "  'Name': 'Sharone',\n",
       "  'Age': 24,\n",
       "  'Birth year': 1998,\n",
       "  'Job post': 'Truck operator'}]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After update\n",
    "list(sample.find({'Name':'Sharone'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364ae405",
   "metadata": {},
   "source": [
    "### 3. Update part of multiple documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "cbdb7914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': ObjectId('616f94634108a89cfa3aee29'),\n",
       "  'Name': 'Tammy',\n",
       "  'Age': 27,\n",
       "  'Birth year': 1978,\n",
       "  'Job post': 'Engineer'},\n",
       " {'_id': ObjectId('616f94bc4108a89cfa3aee2a'),\n",
       "  'Name': 'Cynthia',\n",
       "  'Age': 27,\n",
       "  'Birth year': 1978,\n",
       "  'Job post': 'Engineer'}]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before update\n",
    "list(sample.find({'Job post':'Engineer'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "45e3d3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiupdate = sample.update_many({'Job post':'Engineer'},{'$set':{'Job post': 'Architect', 'Age': 25}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "347e2e80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n': 2,\n",
       " 'nModified': 2,\n",
       " 'opTime': {'ts': Timestamp(1634719276, 2), 't': 106},\n",
       " 'electionId': ObjectId('7fffffff000000000000006a'),\n",
       " 'ok': 1.0,\n",
       " '$clusterTime': {'clusterTime': Timestamp(1634719276, 2),\n",
       "  'signature': {'hash': b'\\xa1\\xae\\xc3]\\xb6S\\x844\\xf4s\\x97W\\x8b\\xb3\\xdb\\xb8\\x1a\\xf3\\xba\\xe7',\n",
       "   'keyId': 6961454422681452546}},\n",
       " 'operationTime': Timestamp(1634719276, 2),\n",
       " 'updatedExisting': True}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiupdate.raw_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5e3b556c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': ObjectId('616f94634108a89cfa3aee29'),\n",
       "  'Name': 'Tammy',\n",
       "  'Age': 25,\n",
       "  'Birth year': 1978,\n",
       "  'Job post': 'Architect'},\n",
       " {'_id': ObjectId('616f94bc4108a89cfa3aee2a'),\n",
       "  'Name': 'Cynthia',\n",
       "  'Age': 25,\n",
       "  'Birth year': 1978,\n",
       "  'Job post': 'Architect'}]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After update\n",
    "list(sample.find({'Job post':'Architect'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3656fd41",
   "metadata": {},
   "source": [
    "Note that update operations by default will not result in any documents modified if none of the existing documents satisfies the condition specified, where \"upsert\" key value is set to False.\n",
    "\n",
    "<b> By setting \"upsert\" key value to True, new documents will be created when none of the existing documents meet the criteria specified. </b>\n",
    "\n",
    "The example below demonstrates the use of \"upsert\" key value as true:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3e8e06d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n': 0,\n",
       " 'nModified': 0,\n",
       " 'opTime': {'ts': Timestamp(1634719496, 1), 't': 106},\n",
       " 'electionId': ObjectId('7fffffff000000000000006a'),\n",
       " 'ok': 1.0,\n",
       " '$clusterTime': {'clusterTime': Timestamp(1634719496, 1),\n",
       "  'signature': {'hash': b'/[\\xb2\\xc4^\\xeaP\\x1e\\ta\\xb5,\\xf9%\\x0e\\xd1\\x86\\x17gB',\n",
       "   'keyId': 6961454422681452546}},\n",
       " 'operationTime': Timestamp(1634719496, 1),\n",
       " 'updatedExisting': False}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.update_many({'Age':'35'},{'$set':{'Job post': 'Architect', 'Birth year':1989}}).raw_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981ff6ca",
   "metadata": {},
   "source": [
    "<b> From the operation above, none of the existing documents have age key value as 35. Thus, no documents are modified (nModified is 0) and no documents are inserted (n is 0). </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "09889ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n': 1,\n",
       " 'nModified': 0,\n",
       " 'upserted': ObjectId('616fd74a51fd68b2c7e398d3'),\n",
       " 'opTime': {'ts': Timestamp(1634719562, 29), 't': 106},\n",
       " 'electionId': ObjectId('7fffffff000000000000006a'),\n",
       " 'ok': 1.0,\n",
       " '$clusterTime': {'clusterTime': Timestamp(1634719562, 29),\n",
       "  'signature': {'hash': b'\\x0e(\\xcb\\x82\\x06\\xbf&S(\\xc9\\x19\\xae\\xbf\\xffTC\\x84&\\xae\\x12',\n",
       "   'keyId': 6961454422681452546}},\n",
       " 'operationTime': Timestamp(1634719562, 29),\n",
       " 'updatedExisting': False}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.update_many({'Age':'35'},{'$set':{'Job post': 'Architect', 'Birth year':1989}}, upsert=True).raw_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "98421fd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': ObjectId('616fd74a51fd68b2c7e398d3'),\n",
       "  'Age': '35',\n",
       "  'Birth year': 1989,\n",
       "  'Job post': 'Architect'}]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After update operation with upsert value as True\n",
    "list(sample.find({'Age':'35'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0e9ef0",
   "metadata": {},
   "source": [
    "<b> From the update operation above, a new document is inserted into the collection (n=1) since none of the previous existing documents have age key value as 35. </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70838b59",
   "metadata": {},
   "source": [
    "## Update Operators of MongoDB\n",
    "\n",
    "Besides using $set operator, there are other update operators available in MongoDB as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2962e92",
   "metadata": {},
   "source": [
    "### 1. Increment values - INC\n",
    "Values can be incremented in positive or negative values as per example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5d78ebc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': 3,\n",
       "  'Name': 'McBethy',\n",
       "  'Age': 27,\n",
       "  'Occupation': 'Doctor',\n",
       "  'Income': 27000}]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before update\n",
    "list(sample.find({'Name':'McBethy'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cd4484",
   "metadata": {},
   "source": [
    "The operation below adds additional income of McBethy by 10000 from 27000 to 37000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b669a33f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n': 1,\n",
       " 'nModified': 1,\n",
       " 'opTime': {'ts': Timestamp(1634726286, 26), 't': 106},\n",
       " 'electionId': ObjectId('7fffffff000000000000006a'),\n",
       " 'ok': 1.0,\n",
       " '$clusterTime': {'clusterTime': Timestamp(1634726286, 26),\n",
       "  'signature': {'hash': b'\" \\x13a\\xad&\\xc48+\\x1bm\\xbc<\\x02>\\xe5\\xfc\\xad\\xfb\\xd7',\n",
       "   'keyId': 6961454422681452546}},\n",
       " 'operationTime': Timestamp(1634726286, 26),\n",
       " 'updatedExisting': True}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.update_one({'Name': 'McBethy'},{'$inc': {'Income': 10000}}).raw_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "d297b5e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': 3,\n",
       "  'Name': 'McBethy',\n",
       "  'Age': 27,\n",
       "  'Occupation': 'Doctor',\n",
       "  'Income': 37000}]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After update\n",
    "list(sample.find({'Name':'McBethy'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e700eaae",
   "metadata": {},
   "source": [
    "The operation below reduces McBethy's income by 2000 from 37000 to 35000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f13d40d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n': 1,\n",
       " 'nModified': 1,\n",
       " 'opTime': {'ts': Timestamp(1634726320, 1), 't': 106},\n",
       " 'electionId': ObjectId('7fffffff000000000000006a'),\n",
       " 'ok': 1.0,\n",
       " '$clusterTime': {'clusterTime': Timestamp(1634726320, 1),\n",
       "  'signature': {'hash': b'\\x96\\xfaIr\\x82!5\\xd0\\x94\\rr 8\\xe2I%LwV\\xb4',\n",
       "   'keyId': 6961454422681452546}},\n",
       " 'operationTime': Timestamp(1634726320, 1),\n",
       " 'updatedExisting': True}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.update_one({'Name': 'McBethy'},{'$inc': {'Income': -2000}}).raw_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "600195f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': 3,\n",
       "  'Name': 'McBethy',\n",
       "  'Age': 27,\n",
       "  'Occupation': 'Doctor',\n",
       "  'Income': 35000}]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After update\n",
    "list(sample.find({'Name':'McBethy'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884adf4d",
   "metadata": {},
   "source": [
    "### 2. Multiply values - MUL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c3119141",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': ObjectId('616f95554108a89cfa3aee2f'),\n",
       "  'Name': 'Crempie',\n",
       "  'Age': 22,\n",
       "  'Birth year': 1998,\n",
       "  'Job post': 'Business Analyst'}]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before update\n",
    "list(sample.find({'Name':'Crempie'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569dccc7",
   "metadata": {},
   "source": [
    "The operation below multiplies the age of Crempie by 2 from 22 to 44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "88ae875e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n': 1,\n",
       " 'nModified': 1,\n",
       " 'opTime': {'ts': Timestamp(1634726661, 1), 't': 106},\n",
       " 'electionId': ObjectId('7fffffff000000000000006a'),\n",
       " 'ok': 1.0,\n",
       " '$clusterTime': {'clusterTime': Timestamp(1634726661, 1),\n",
       "  'signature': {'hash': b'\\x15u\\x9e\\xed\\x9a\\xb5\\xb7\\xcb\\xfd\\xd7\\xfc#q\\xbfd%|8\\x95\\x8b',\n",
       "   'keyId': 6961454422681452546}},\n",
       " 'operationTime': Timestamp(1634726661, 1),\n",
       " 'updatedExisting': True}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.update_one({'Name': 'Crempie'},{'$mul': {'Age': 2}}).raw_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f674e162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': ObjectId('616f95554108a89cfa3aee2f'),\n",
       "  'Name': 'Crempie',\n",
       "  'Age': 44,\n",
       "  'Birth year': 1998,\n",
       "  'Job post': 'Business Analyst'}]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After update\n",
    "list(sample.find({'Name':'Crempie'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c6b1d1",
   "metadata": {},
   "source": [
    "### 3. Remove field from document - Unset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "00367f02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': 3,\n",
       "  'Name': 'McBethy',\n",
       "  'Age': 27,\n",
       "  'Occupation': 'Doctor',\n",
       "  'Income': 35000}]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before update\n",
    "list(sample.find({'Name':'McBethy'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcc83d6",
   "metadata": {},
   "source": [
    "The operation below removes the age field for McBethy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "fc3a56bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n': 1,\n",
       " 'nModified': 1,\n",
       " 'opTime': {'ts': Timestamp(1634731090, 1), 't': 106},\n",
       " 'electionId': ObjectId('7fffffff000000000000006a'),\n",
       " 'ok': 1.0,\n",
       " '$clusterTime': {'clusterTime': Timestamp(1634731090, 1),\n",
       "  'signature': {'hash': b'&\\xbc\\x16\\xf4u\\xd4<v\\r\\xcfa\\x17Zi9G\\xf48\\x85I',\n",
       "   'keyId': 6961454422681452546}},\n",
       " 'operationTime': Timestamp(1634731090, 1),\n",
       " 'updatedExisting': True}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.update_one({'Name': 'McBethy'},{'$unset': {'Age': 1}}).raw_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "13826df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': 3, 'Name': 'McBethy', 'Occupation': 'Doctor', 'Income': 35000}]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After update\n",
    "list(sample.find({'Name':'McBethy'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510fd097",
   "metadata": {},
   "source": [
    "### 4. Adding timestamp on documents - currentDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "36f4ea25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': 3, 'Name': 'McBethy', 'Occupation': 'Doctor', 'Income': 35000}]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before update\n",
    "list(sample.find({'Name':'McBethy'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcf5a88",
   "metadata": {},
   "source": [
    "The operation below updates McBethy's info to show the latest update in datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "3cfa43e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n': 1,\n",
       " 'nModified': 1,\n",
       " 'opTime': {'ts': Timestamp(1634731577, 1), 't': 106},\n",
       " 'electionId': ObjectId('7fffffff000000000000006a'),\n",
       " 'ok': 1.0,\n",
       " '$clusterTime': {'clusterTime': Timestamp(1634731577, 1),\n",
       "  'signature': {'hash': b'O\\xba&\\x95\\xb8A\\xfc;\\xb8\\x06^+YS\\x88P\\x04\\x02rV',\n",
       "   'keyId': 6961454422681452546}},\n",
       " 'operationTime': Timestamp(1634731577, 1),\n",
       " 'updatedExisting': True}"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.update_one({'Name': 'McBethy'},{'$currentDate': {\"lastupdate\": {'$type': \"date\" }}}).raw_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "2f062908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': 3,\n",
       "  'Name': 'McBethy',\n",
       "  'Occupation': 'Doctor',\n",
       "  'Income': 35000,\n",
       "  'lastupdate': datetime.datetime(2021, 10, 20, 12, 6, 17, 206000)}]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After update\n",
    "list(sample.find({'Name':'McBethy'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342a7d58",
   "metadata": {},
   "source": [
    "### 5. Update operations with arrays\n",
    "\n",
    "#### i) Add single item to a new/existing array - push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "14b6964a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': ObjectId('616f95554108a89cfa3aee2d'),\n",
       "  'Name': 'Chloe',\n",
       "  'Age': 19,\n",
       "  'Birth year': 2002,\n",
       "  'Job post': 'Student'}]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before update\n",
    "list(sample.find({'Name':'Chloe'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8b3061",
   "metadata": {},
   "source": [
    "The operation below adds biscuits to a new array field named as items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "8249642a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n': 1,\n",
       " 'nModified': 1,\n",
       " 'opTime': {'ts': Timestamp(1634731759, 5), 't': 106},\n",
       " 'electionId': ObjectId('7fffffff000000000000006a'),\n",
       " 'ok': 1.0,\n",
       " '$clusterTime': {'clusterTime': Timestamp(1634731759, 5),\n",
       "  'signature': {'hash': b'\\xea\\xbav\\x03Z\\x0f\\xbb2\\xcf\\x14*\\x12\\xa0W\\x90@\\x1b\\xf5\\xe2|',\n",
       "   'keyId': 6961454422681452546}},\n",
       " 'operationTime': Timestamp(1634731759, 5),\n",
       " 'updatedExisting': True}"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.update_one({'Name': 'Chloe'},{'$push': {\"items\": 'biscuits'}}).raw_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "a1958af7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': ObjectId('616f95554108a89cfa3aee2d'),\n",
       "  'Name': 'Chloe',\n",
       "  'Age': 19,\n",
       "  'Birth year': 2002,\n",
       "  'Job post': 'Student',\n",
       "  'items': ['biscuits']}]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After update\n",
    "list(sample.find({'Name':'Chloe'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebedcd4",
   "metadata": {},
   "source": [
    "The operation below adds fruits to an existing array field \"items\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "a88542d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n': 1,\n",
       " 'nModified': 1,\n",
       " 'opTime': {'ts': Timestamp(1634731794, 1), 't': 106},\n",
       " 'electionId': ObjectId('7fffffff000000000000006a'),\n",
       " 'ok': 1.0,\n",
       " '$clusterTime': {'clusterTime': Timestamp(1634731794, 1),\n",
       "  'signature': {'hash': b'\\x91.b8\\xfdIJ=\\xa6\\xc7\\xb3\\xde\\x991\\xe5#`B\\x7f6',\n",
       "   'keyId': 6961454422681452546}},\n",
       " 'operationTime': Timestamp(1634731794, 1),\n",
       " 'updatedExisting': True}"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.update_one({'Name': 'Chloe'},{'$push': {\"items\": 'fruits'}}).raw_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "522b28fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': ObjectId('616f95554108a89cfa3aee2d'),\n",
       "  'Name': 'Chloe',\n",
       "  'Age': 19,\n",
       "  'Birth year': 2002,\n",
       "  'Job post': 'Student',\n",
       "  'items': ['biscuits', 'fruits']}]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After update\n",
    "list(sample.find({'Name':'Chloe'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b36dac",
   "metadata": {},
   "source": [
    "#### ii) Add multiple items to an array - push + each"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c28312",
   "metadata": {},
   "source": [
    "The operation below adds multiple elements into \"items\" array field at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "0f998f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n': 1,\n",
       " 'nModified': 1,\n",
       " 'opTime': {'ts': Timestamp(1634731897, 1), 't': 106},\n",
       " 'electionId': ObjectId('7fffffff000000000000006a'),\n",
       " 'ok': 1.0,\n",
       " '$clusterTime': {'clusterTime': Timestamp(1634731897, 1),\n",
       "  'signature': {'hash': b'\\x190\\xa79e 0\\xfcw\\xe5\\xb3\\x11%\\xa54!X\\xe6\\xe5\\xa8',\n",
       "   'keyId': 6961454422681452546}},\n",
       " 'operationTime': Timestamp(1634731897, 1),\n",
       " 'updatedExisting': True}"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.update_one({'Name': 'Chloe'},{'$push': {\"items\": {\"$each\": ['apple','cake','mandarin']}}}).raw_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "03e9b9c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': ObjectId('616f95554108a89cfa3aee2d'),\n",
       "  'Name': 'Chloe',\n",
       "  'Age': 19,\n",
       "  'Birth year': 2002,\n",
       "  'Job post': 'Student',\n",
       "  'items': ['biscuits', 'fruits', 'apple', 'cake', 'mandarin']}]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After update\n",
    "list(sample.find({'Name':'Chloe'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b51aee4",
   "metadata": {},
   "source": [
    "#### iii) Add unique items to an array - addToSet + each"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c14467",
   "metadata": {},
   "source": [
    "The operation below adds multiple elements that are unique into \"items\" array field at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "c6df0334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n': 1,\n",
       " 'nModified': 1,\n",
       " 'opTime': {'ts': Timestamp(1634731964, 1000), 't': 106},\n",
       " 'electionId': ObjectId('7fffffff000000000000006a'),\n",
       " 'ok': 1.0,\n",
       " '$clusterTime': {'clusterTime': Timestamp(1634731964, 1000),\n",
       "  'signature': {'hash': b'\\xd0[\\xbel\\xe4\\x85\\xe8\\x842\\x11\\xa4S\\xe9\\xd4\\xd0U\\xa8\\x93\\xect',\n",
       "   'keyId': 6961454422681452546}},\n",
       " 'operationTime': Timestamp(1634731964, 1000),\n",
       " 'updatedExisting': True}"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.update_one({'Name': 'Chloe'},{'$addToSet': {\"items\": {\"$each\": ['apple','noodles','guava','biscuits']}}}).raw_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "8f90e40f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': ObjectId('616f95554108a89cfa3aee2d'),\n",
       "  'Name': 'Chloe',\n",
       "  'Age': 19,\n",
       "  'Birth year': 2002,\n",
       "  'Job post': 'Student',\n",
       "  'items': ['biscuits',\n",
       "   'fruits',\n",
       "   'apple',\n",
       "   'cake',\n",
       "   'mandarin',\n",
       "   'noodles',\n",
       "   'guava']}]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After update\n",
    "list(sample.find({'Name':'Chloe'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19df93d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
